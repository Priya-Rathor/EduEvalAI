{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_tracing_context' from 'langsmith.run_helpers' (c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langsmith\\run_helpers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  StateGraph, START, END\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModel\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\graph\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m END, START, Graph\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessageGraph, MessagesState, add_messages\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StateGraph\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\graph\\graph.py:39\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     EMPTY_SEQ,\n\u001b[0;32m     31\u001b[0m     END,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     Send,\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InvalidUpdateError\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpregel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Channel, Pregel\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpregel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mread\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PregelNode\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpregel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChannelWrite, ChannelWriteEntry\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\__init__.py:40\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Graph\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     37\u001b[0m     ConfigurableFieldSpec,\n\u001b[0;32m     38\u001b[0m     get_unique_config_specs,\n\u001b[0;32m     39\u001b[0m )\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_streaming\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _StreamingCallbackHandler\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Self\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\tracers\\__init__.py:22\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"**Tracers** are classes for tracing runs.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m**Class hierarchy:**\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m                                       --> <name>  # Examples: LogStreamCallbackHandler\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m     11\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseTracer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluatorCallbackHandler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogStreamCallbackHandler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m ]\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseTracer\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvaluatorCallbackHandler\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LangChainTracer\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\tracers\\base.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01muuid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UUID\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtenacity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RetryCallState\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsyncCallbackHandler, BaseCallbackHandler\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TracerException  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseMessage\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\callbacks\\__init__.py:23\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     AsyncCallbackHandler,\n\u001b[0;32m     12\u001b[0m     BaseCallbackHandler,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     ToolManagerMixin,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileCallbackHandler\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     AsyncCallbackManager,\n\u001b[0;32m     25\u001b[0m     AsyncCallbackManagerForChainGroup,\n\u001b[0;32m     26\u001b[0m     AsyncCallbackManagerForChainRun,\n\u001b[0;32m     27\u001b[0m     AsyncCallbackManagerForLLMRun,\n\u001b[0;32m     28\u001b[0m     AsyncCallbackManagerForRetrieverRun,\n\u001b[0;32m     29\u001b[0m     AsyncCallbackManagerForToolRun,\n\u001b[0;32m     30\u001b[0m     AsyncParentRunManager,\n\u001b[0;32m     31\u001b[0m     AsyncRunManager,\n\u001b[0;32m     32\u001b[0m     BaseRunManager,\n\u001b[0;32m     33\u001b[0m     CallbackManager,\n\u001b[0;32m     34\u001b[0m     CallbackManagerForChainGroup,\n\u001b[0;32m     35\u001b[0m     CallbackManagerForChainRun,\n\u001b[0;32m     36\u001b[0m     CallbackManagerForLLMRun,\n\u001b[0;32m     37\u001b[0m     CallbackManagerForRetrieverRun,\n\u001b[0;32m     38\u001b[0m     CallbackManagerForToolRun,\n\u001b[0;32m     39\u001b[0m     ParentRunManager,\n\u001b[0;32m     40\u001b[0m     RunManager,\n\u001b[0;32m     41\u001b[0m     adispatch_custom_event,\n\u001b[0;32m     42\u001b[0m     dispatch_custom_event,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstdout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StdOutCallbackHandler\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming_stdout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StreamingStdOutCallbackHandler\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\callbacks\\manager.py:23\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     TYPE_CHECKING,\n\u001b[0;32m     14\u001b[0m     Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     cast,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01muuid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UUID\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangsmith\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrun_helpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tracing_context\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtenacity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RetryCallState\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     BaseCallbackHandler,\n\u001b[0;32m     28\u001b[0m     BaseCallbackManager,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     ToolManagerMixin,\n\u001b[0;32m     35\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_tracing_context' from 'langsmith.run_helpers' (c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langsmith\\run_helpers.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from typing import TypedDict\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langgraph.graph import  StateGraph, START, END\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputState(TypedDict):\n",
    "    suggested_answer:str\n",
    "    student_answer:str\n",
    "\n",
    "class OutputState(TypedDict):\n",
    "    llm_score: float\n",
    "    llm_feedback: str\n",
    "    bart_score:float\n",
    "    bert_score:float\n",
    "    roberta_score:float\n",
    "    t5_score:float\n",
    "    embsdding_similarity_sroce: float\n",
    "    hybrid_score:float\n",
    "\n",
    "class OverallState(InputState,OutputState):\n",
    "    pass\n",
    "\n",
    "\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\llms\\openai.py:255: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\llms\\openai.py:1086: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_19476\\731476925.py:16: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=scoring_prompt)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.globals'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Initialize LLM and embeddings through LangChain\u001b[39;00m\n\u001b[0;32m     15\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m chain \u001b[38;5;241m=\u001b[39m \u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings()\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:216\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     emit_warning()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\base.py:44\u001b[0m, in \u001b[0;36m_get_verbosity\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mChain\u001b[39;00m(Serializable, Runnable[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Dict[\u001b[38;5;28mstr\u001b[39m, Any]], ABC):\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Abstract base class for creating structured sequences of calls to components.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    Chains should be used to encode a sequence of calls to components like\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    models, document retrievers, other chains, etc., and provide a simple interface\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    to this sequence.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m    The Chain interface makes it easy to create apps that are:\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;124;03m        - Stateful: add Memory to any Chain to give it state,\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m        - Observable: pass Callbacks to a Chain to execute additional functionality,\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m            like logging, outside the main sequence of component calls,\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m        - Composable: the Chain API is flexible enough that it is easy to combine\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m            Chains with other components, including other Chains.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    The main methods exposed by chains are:\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m        - `__call__`: Chains are callable. The `__call__` method is the primary way to\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m            execute a Chain. This takes inputs as a dictionary and returns a\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m            dictionary output.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m        - `run`: A convenience method that takes inputs as args/kwargs and returns the\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m            output as a string or object. This method can only be used for a subset of\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m            chains and cannot return as rich of an output as `__call__`.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28minput\u001b[39m: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m     62\u001b[0m         config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m     64\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m     65\u001b[0m         config \u001b[38;5;241m=\u001b[39m config \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain.globals'"
     ]
    }
   ],
   "source": [
    "# Define a prompt template for LLM evaluation\n",
    "scoring_prompt = PromptTemplate(\n",
    "    input_variables=[\"suggested_answer\", \"student_answer\"],\n",
    "    template=\"\"\"\n",
    "Suggested answer: \"{suggested_answer}\"\n",
    "Student’s answer: \"{student_answer}\"\n",
    "\n",
    "Evaluate how well the student’s answer matches the suggested answer on a scale from 0 to 10,\n",
    "considering correctness, completeness, and clarity. Provide a numeric score followed by a one-line feedback.\n",
    "Example: \"8.5 - Good answer but slightly lacks depth.\"\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Initialize LLM and embeddings through LangChain\n",
    "llm = OpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "chain = LLMChain(llm=llm, prompt=scoring_prompt)\n",
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Hugging Face tokenizer and models\n",
    "def load_model_and_tokenizer(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    return tokenizer, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bart_tokenizer, bart_model = load_model_and_tokenizer(\"facebook/bart-large\")\n",
    "bert_tokenizer, bert_model = load_model_and_tokenizer(\"bert-base-uncased\")\n",
    "roberta_tokenizer, roberta_model = load_model_and_tokenizer(\"roberta-base\")\n",
    "t5_tokenizer, t5_model = load_model_and_tokenizer(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(embedding1, embedding2):\n",
    "    \"\"\"Utility to compute cosine similarity.\"\"\"\n",
    "    dot = torch.dot(embedding1, embedding2).item()\n",
    "    norm1 = torch.norm(embedding1).item()\n",
    "    norm2 = torch.norm(embedding2).item()\n",
    "    return dot / (norm1 * norm2) if norm1 and norm2 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_evaluation_node(state: OverallState) -> dict:\n",
    "    suggested_answer = state['suggested_answer']\n",
    "    student_answer = state['student_answer']\n",
    "    \"\"\"Use LLMChain to evaluate student answer and return llm_score with feedback.\"\"\"\n",
    "    response = chain.run(suggested_answer=suggested_answer, student_answer=student_answer).strip()\n",
    "    try:\n",
    "        score, feedback = response.split(\" - \", 1)\n",
    "        score = float(score)\n",
    "    except ValueError:\n",
    "        score = 0.0\n",
    "        feedback = \"No valid feedback.\"\n",
    "    return {\"llm_score\": score, \"llm_feedback\": feedback}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bart_evaluation_node(state: OverallState) -> dict:\n",
    "    suggested_answer = state['suggested_answer']\n",
    "    student_answer = state['student_answer']\n",
    "    \"\"\"Evaluate using BART embeddings.\"\"\"\n",
    "    inputs = bart_tokenizer(suggested_answer, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = bart_model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    # Assuming you want to compare embeddings\n",
    "    student_inputs = bart_tokenizer(student_answer, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        student_outputs = bart_model(**student_inputs)\n",
    "        student_embeddings = student_outputs.last_hidden_state.mean(dim=1)\n",
    "    score = compute_cosine_similarity(embeddings[0], student_embeddings[0])\n",
    "    return {\"bart_score\": score * 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_evaluation_node(state:OverallState) -> dict:\n",
    "    suggested_answer = state['suggested_answer']\n",
    "    student_answer = state['student_answer']\n",
    "    \"\"\"Evaluate using BERT embeddings.\"\"\"\n",
    "    inputs = bert_tokenizer([suggested_answer, student_answer], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    score = compute_cosine_similarity(embeddings[0], embeddings[1])\n",
    "    return {\"bert_score\": score * 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_cosine_similarity(embedding1, embedding2):\n",
    "    return cosine_similarity(embedding1.unsqueeze(0).detach().numpy(), embedding2.unsqueeze(0).detach().numpy())[0][0]\n",
    "\n",
    "def roberta_evaluation_node(state:OverallState) -> dict:\n",
    "    suggested_answer = state['suggested_answer']\n",
    "    student_answer = state['student_answer']\n",
    "    \"\"\"Evaluate using RoBERTa embeddings.\"\"\"\n",
    "    inputs = roberta_tokenizer([suggested_answer, student_answer], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = roberta_model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    score = compute_cosine_similarity(embeddings[0], embeddings[1])\n",
    "    return {\"roberta_score\": score * 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def t5_evaluation_node(state: InputState) -> dict:\n",
    "    suggested_answer = state['suggested_answer']\n",
    "    student_answer = state['student_answer']\n",
    "    \"\"\"Evaluate using T5 embeddings.\"\"\"\n",
    "    inputs = t5_tokenizer(suggested_answer, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = t5_model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    student_inputs = t5_tokenizer(student_answer, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        student_outputs = t5_model(**student_inputs)\n",
    "        student_embeddings = student_outputs.last_hidden_state.mean(dim=1)\n",
    "    score = compute_cosine_similarity(embeddings[0], student_embeddings[0])\n",
    "    return {\"t5_score\": score * 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_similarity_evaluation_node(state: OverallState) -> dict:\n",
    "    suggested_answer = state['suggested_answer']\n",
    "    student_answer = state['student_answer']\n",
    "    \"\"\"Evaluate using OpenAI embeddings.\"\"\"\n",
    "    vecs = embeddings.embed_documents([suggested_answer, student_answer])\n",
    "    sim = compute_cosine_similarity(torch.tensor(vecs[0]), torch.tensor(vecs[1]))\n",
    "    return {\"embedding_similarity_score\": sim * 10.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_evaluation_node(llm_score: float, embedding_similarity_score: float) -> dict:\n",
    "    \"\"\"Combine LLM score and embedding similarity score.\"\"\"\n",
    "    return {\"hybrid_score\": (llm_score + embedding_similarity_score) / 2.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StateGraph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m builder \u001b[38;5;241m=\u001b[39m \u001b[43mStateGraph\u001b[49m(OverallState, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mInputState, output\u001b[38;5;241m=\u001b[39mOutputState)\n\u001b[0;32m      3\u001b[0m builder\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_node\u001b[39m\u001b[38;5;124m\"\u001b[39m, llm_evaluation_node)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#builder.add_node(\"embedding_node\", embedding_similarity_evaluation_node)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StateGraph' is not defined"
     ]
    }
   ],
   "source": [
    "builder = StateGraph(OverallState, input=InputState, output=OutputState)\n",
    "\n",
    "builder.add_node(\"llm_node\", llm_evaluation_node)\n",
    "#builder.add_node(\"embedding_node\", embedding_similarity_evaluation_node)\n",
    "builder.add_node(\"bart_node\", bart_evaluation_node)\n",
    "#builder.add_node(\"bert_node\", bert_evaluation_node)\n",
    "#builder.add_node(\"roberta_node\", roberta_evaluation_node)\n",
    "#builder.add_node(\"t5_node\", t5_evaluation_node)\n",
    "#builder.add_node(\"hybrid_node\", hybrid_evaluation_node)\n",
    "\n",
    "# Define edges\n",
    "builder.add_edge(START, \"llm_node\")\n",
    "#builder.add_edge(START, \"embedding_node\")\n",
    "builder.add_edge(\"llm_node\", \"bart_node\")\n",
    "#builder.add_edge(START, \"bert_node\")\n",
    "#builder.add_edge(START, \"roberta_node\")\n",
    "#builder.add_edge(START, \"t5_node\")\n",
    "\n",
    "\n",
    "builder.add_edge(\"llm_node\", END)\n",
    "#builder.add_edge(\"embedding_node\", \"hybrid_node\")\n",
    "builder.add_edge(\"bart_node\",END)\n",
    "#builder.add_edge(\"bert_node\",\"hybrid_node\")\n",
    "#builder.add_edge(\"roberta_node\",\"hybrid_node\")\n",
    "#builder.add_edge(\"t5_node\",\"hybrid_node\")\n",
    "\n",
    "#builder.add_edge(\"hybrid_node\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuggested_answer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReaching the Target Audience: Affiliate marketing can extend the organization’s reach into new and existing market segments through affiliates who already have the trust and attention of these audiences. By partnering with affiliates that align with the organization’s target demographics and interests, the organization can efficiently broaden its reach.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mDriving Sales: Affiliates drive sales by leveraging their platforms (such as blogs, social media, email lists) to promote the organization’s products or services. Effective affiliates turn their audience’s trust into action, guiding them through the sales funnel. Strategies here include exclusive affiliate promotions, product reviews, and personalized affiliate links that track conversions.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstudent_answer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAffiliate marketing is an effective strategy for organizations to reach their target audience and drive sales. By leveraging the trust and credibility of affiliates, businesses can expand their reach into both new and existing market segments. Affiliates, who already have established relationships with their audiences, serve as valuable partners in promoting products or services. Partnering with affiliates that align with the organization’s target demographics and interests ensures an efficient way to broaden the reach and establish a stronger presence in specific markets.Additionally, affiliate marketing is a powerful tool for driving sales. Affiliates utilize their platforms—such as blogs, social media, and email lists—to endorse and promote the organization’s offerings. This trusted endorsement often translates into audience action, moving potential customers through the sales funnel. Effective strategies employed by affiliates include offering exclusive promotions, writing product reviews, and using personalized affiliate links to track conversions. These methods not only enhance visibility but also ensure measurable outcomes for the organization.By partnering with affiliates who share similar values and appeal to the desired audience, businesses can effectively maximize their marketing efforts, build trust with potential customers, and achieve significant growth in sales and market reach. This mutually beneficial model drives results efficiently and sustainably.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1936\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1934\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1935\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1936\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   1937\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1938\u001b[0m     config,\n\u001b[0;32m   1939\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   1940\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   1941\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   1942\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   1943\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1947\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1656\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1650\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1652\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1656\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1657\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1658\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1659\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1660\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1661\u001b[0m         ):\n\u001b[0;32m   1662\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1663\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1664\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\runner.py:239\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    237\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdone_futures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpanic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\runner.py:539\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(futs, timeout_exc_cls, panic)\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m panic:\n\u001b[1;32m--> 539\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[0;32m    543\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\executor.py:76\u001b[0m, in \u001b[0;36mBackgroundExecutor.done\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdone\u001b[39m(\u001b[38;5;28mself\u001b[39m, task: concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mFuture) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m         \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m GraphBubbleUp:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mpop(task)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\utils\\runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m )\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\utils\\runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[27], line 5\u001b[0m, in \u001b[0;36mllm_evaluation_node\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      3\u001b[0m student_answer \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudent_answer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use LLMChain to evaluate student answer and return llm_score with feedback.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43msuggested_answer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuggested_answer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent_answer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudent_answer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     score, feedback \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     emit_warning()\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\base.py:611\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    607\u001b[0m         _output_key\n\u001b[0;32m    608\u001b[0m     ]\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    612\u001b[0m         _output_key\n\u001b[0;32m    613\u001b[0m     ]\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    617\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    618\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    619\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     emit_warning()\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\llm.py:126\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    123\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    124\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 126\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    136\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    139\u001b[0m         prompts,\n\u001b[0;32m    140\u001b[0m         stop,\n\u001b[0;32m    141\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[0;32m    143\u001b[0m     )\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    146\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    147\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\llms.py:755\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    749\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    753\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    754\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\llms.py:950\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    936\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    937\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    938\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    948\u001b[0m         )\n\u001b[0;32m    949\u001b[0m     ]\n\u001b[1;32m--> 950\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[0;32m    951\u001b[0m         prompts, stop, run_managers, \u001b[38;5;28mbool\u001b[39m(new_arg_supported), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    952\u001b[0m     )\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\llms.py:792\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[0;32m    791\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 792\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    793\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\llms.py:779\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    771\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    775\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    776\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    778\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 779\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    780\u001b[0m                 prompts,\n\u001b[0;32m    781\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    782\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[0;32m    783\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    784\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    785\u001b[0m             )\n\u001b[0;32m    786\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    787\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    788\u001b[0m         )\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\llms\\openai.py:1175\u001b[0m, in \u001b[0;36mOpenAIChat._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1173\u001b[0m messages, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_chat_params(prompts, stop)\n\u001b[0;32m   1174\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m-> 1175\u001b[0m full_response \u001b[38;5;241m=\u001b[39m completion_with_retry(\n\u001b[0;32m   1176\u001b[0m     \u001b[38;5;28mself\u001b[39m, messages\u001b[38;5;241m=\u001b[39mmessages, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m   1177\u001b[0m )\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(full_response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m   1179\u001b[0m     full_response \u001b[38;5;241m=\u001b[39m full_response\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\llms\\openai.py:121\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[1;34m(llm, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    123\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(llm, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "data=graph.invoke({\n",
    "\"suggested_answer\": \"Reaching the Target Audience: Affiliate marketing can extend the organization’s reach into new and existing market segments through affiliates who already have the trust and attention of these audiences. By partnering with affiliates that align with the organization’s target demographics and interests, the organization can efficiently broaden its reach.\\n\\nDriving Sales: Affiliates drive sales by leveraging their platforms (such as blogs, social media, email lists) to promote the organization’s products or services. Effective affiliates turn their audience’s trust into action, guiding them through the sales funnel. Strategies here include exclusive affiliate promotions, product reviews, and personalized affiliate links that track conversions.\",\n",
    "\"student_answer\":\"Affiliate marketing is an effective strategy for organizations to reach their target audience and drive sales. By leveraging the trust and credibility of affiliates, businesses can expand their reach into both new and existing market segments. Affiliates, who already have established relationships with their audiences, serve as valuable partners in promoting products or services. Partnering with affiliates that align with the organization’s target demographics and interests ensures an efficient way to broaden the reach and establish a stronger presence in specific markets.Additionally, affiliate marketing is a powerful tool for driving sales. Affiliates utilize their platforms—such as blogs, social media, and email lists—to endorse and promote the organization’s offerings. This trusted endorsement often translates into audience action, moving potential customers through the sales funnel. Effective strategies employed by affiliates include offering exclusive promotions, writing product reviews, and using personalized affiliate links to track conversions. These methods not only enhance visibility but also ensure measurable outcomes for the organization.By partnering with affiliates who share similar values and appeal to the desired audience, businesses can effectively maximize their marketing efforts, build trust with potential customers, and achieve significant growth in sales and market reach. This mutually beneficial model drives results efficiently and sustainably.\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException,status\n",
    "from fastapi.responses import JSONResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import logging\n",
    "\n",
    "app = FastAPI()\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class EvaluationRequest(BaseModel):\n",
    "    suggested_answer: str\n",
    "    student_answer: str\n",
    "\n",
    "@app.post(\"/evaluate\")\n",
    "async def evaluate_answers(request: EvaluationRequest):\n",
    "    logger.info(\"Received evaluation request: %s\", request.dict())\n",
    "    try:\n",
    "        data = graph.invoke({\n",
    "            \"suggested_answer\": request.suggested_answer,\n",
    "            \"student_answer\": request.student_answer\n",
    "        })\n",
    "        logger.info(\"Evaluation successful: %s\", data)\n",
    "        return JSONResponse(\n",
    "            content={\"message\": \"Item evaluated successfully\", \"data\": data},\n",
    "            status_code=status.HTTP_200_OK\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(\"Error during evaluation: %s\", str(e))\n",
    "        return JSONResponse(\n",
    "            content={\"message\": \"An Error occurred during evaluation\", \"error\": str(e)},\n",
    "            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [19784]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:7500 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:64028 - \"GET / HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64028 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
      "INFO:     127.0.0.1:64028 - \"GET /docs HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:64028 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_19784\\2838657306.py:14: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  logger.info(\"Received evaluation request: %s\", request.dict())\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_19784\\730431094.py:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run(suggested_answer=suggested_answer, student_answer=student_answer).strip()\n",
      "Error during evaluation: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:64029 - \"POST /evaluate HTTP/1.1\" 500 Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_19784\\2838657306.py\", line 16, in evaluate_answers\n",
      "    data = graph.invoke({\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 1936, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\__init__.py\", line 1656, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\runner.py\", line 239, in tick\n",
      "    _panic_or_proceed(\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\runner.py\", line 539, in _panic_or_proceed\n",
      "    raise exc\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\executor.py\", line 76, in done\n",
      "    task.result()\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py\", line 439, in result\n",
      "    return self.__get_result()\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py\", line 391, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\pregel\\retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\utils\\runnable.py\", line 408, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langgraph\\utils\\runnable.py\", line 184, in invoke\n",
      "    ret = context.run(self.func, input, **kwargs)\n",
      "  File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_19784\\730431094.py\", line 5, in llm_evaluation_node\n",
      "    response = chain.run(suggested_answer=suggested_answer, student_answer=student_answer).strip()\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\base.py\", line 611, in run\n",
      "    return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 182, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\base.py\", line 389, in __call__\n",
      "    return self.invoke(\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 755, in generate_prompt\n",
      "    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 950, in generate\n",
      "    output = self._generate_helper(\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 792, in _generate_helper\n",
      "    raise e\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 779, in _generate_helper\n",
      "    self._generate(\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\llms\\openai.py\", line 1175, in _generate\n",
      "    full_response = completion_with_retry(\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\llms\\openai.py\", line 121, in completion_with_retry\n",
      "    return llm.client.create(**kwargs)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\lib\\_old_api.py\", line 39, in __call__\n",
      "    raise APIRemovedInV1(symbol=self._symbol)\n",
      "openai.lib._old_api.APIRemovedInV1: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 409, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\starlette\\applications.py\", line 113, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 187, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 165, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\starlette\\routing.py\", line 715, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\starlette\\routing.py\", line 735, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\starlette\\routing.py\", line 288, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\starlette\\routing.py\", line 76, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\starlette\\routing.py\", line 73, in app\n",
      "    response = await f(request)\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastapi\\routing.py\", line 301, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "  File \"c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\fastapi\\routing.py\", line 212, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "  File \"C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_19784\\2838657306.py\", line 27, in evaluate_answers\n",
      "    return JSONResponse(\n",
      "NameError: name 'JSONResponse' is not defined\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import threading\n",
    "    import uvicorn\n",
    "    threading.Thread(target=lambda: uvicorn.run(app, host=\"127.0.0.1\", port=7500, log_level=\"info\")).start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
